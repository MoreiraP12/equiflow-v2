{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mscipy\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List, Dict, Any, Tuple, Callable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import inspect\n",
    "import re\n",
    "\n",
    "# Import from equiflow package\n",
    "from equiflow import EquiFlow\n",
    "\n",
    "\n",
    "class EasyFlow:\n",
    "    \"\"\"\n",
    "    A simplified interface for creating equity-focused cohort flow diagrams,\n",
    "    building on top of the EquiFlow package with a more user-friendly API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        data: pd.DataFrame, \n",
    "        title: str = \"Cohort Selection\",\n",
    "        auto_detect: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize EasyFlow with a DataFrame and optional title.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            The initial cohort dataframe\n",
    "        title : str, optional\n",
    "            Title for the flow diagram\n",
    "        auto_detect : bool, optional\n",
    "            Whether to automatically detect variable types\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.title = title\n",
    "        self.auto_detect = auto_detect\n",
    "        \n",
    "        # Initialize empty lists for variable types\n",
    "        self._categorical_vars = []\n",
    "        self._normal_vars = []\n",
    "        self._nonnormal_vars = []\n",
    "        \n",
    "        # Track exclusion steps\n",
    "        self._exclusion_steps = []\n",
    "        self._current_data = data\n",
    "        \n",
    "        # Store outputs\n",
    "        self.flow_table = None\n",
    "        self.characteristics = None\n",
    "        self.drifts = None\n",
    "        self.diagram = None\n",
    "        \n",
    "        # Stored EquiFlow instance\n",
    "        self._equiflow = None\n",
    "        \n",
    "        # Auto-detect variable types if enabled\n",
    "        if auto_detect:\n",
    "            self._detect_variable_types()\n",
    "    \n",
    "    def _detect_variable_types(self):\n",
    "        \"\"\"\n",
    "        Automatically detect variable types in the dataframe.\n",
    "        - Categorical: object, bool, or low cardinality numeric\n",
    "        - Normal: numeric variables that pass Shapiro-Wilk test\n",
    "        - Non-normal: numeric variables that fail Shapiro-Wilk test\n",
    "        \"\"\"\n",
    "        # First try the basic categorization without scipy\n",
    "        for col in self.data.columns:\n",
    "            # Skip columns with too many missing values\n",
    "            if self.data[col].isna().mean() > 0.5:\n",
    "                continue\n",
    "                \n",
    "            # Check if column is categorical\n",
    "            if self.data[col].dtype == 'object' or self.data[col].dtype == 'bool':\n",
    "                self._categorical_vars.append(col)\n",
    "                continue\n",
    "                \n",
    "            # Check for low cardinality numeric (likely categorical)\n",
    "            if self.data[col].dtype.kind in 'ifu' and len(self.data[col].unique()) <= 10:\n",
    "                self._categorical_vars.append(col)\n",
    "                continue\n",
    "                \n",
    "            # For numeric columns, add to non-normal by default\n",
    "            if self.data[col].dtype.kind in 'ifu':\n",
    "                self._nonnormal_vars.append(col)\n",
    "        \n",
    "        # Now try to improve categorization with scipy if available\n",
    "        try:\n",
    "            from scipy import stats\n",
    "            \n",
    "            # Clear the normal list to rebuild it\n",
    "            self._normal_vars = []\n",
    "            \n",
    "            # Keep track of columns to remove from non-normal list\n",
    "            to_remove = []\n",
    "            \n",
    "            for col in self._nonnormal_vars:\n",
    "                # Get non-null values\n",
    "                values = self.data[col].dropna()\n",
    "                \n",
    "                # Sample if necessary to speed up test\n",
    "                if len(values) > 5000:\n",
    "                    values = values.sample(5000, random_state=42)\n",
    "                \n",
    "                # Skip if too few values\n",
    "                if len(values) < 8:\n",
    "                    continue\n",
    "                    \n",
    "                # Test for normality\n",
    "                try:\n",
    "                    _, p_value = stats.shapiro(values)\n",
    "                    if p_value > 0.05:  # Normal distribution\n",
    "                        self._normal_vars.append(col)\n",
    "                        to_remove.append(col)\n",
    "                except:\n",
    "                    # If test fails, keep as non-normal\n",
    "                    pass\n",
    "            \n",
    "            # Remove columns from non-normal that are now in normal\n",
    "            self._nonnormal_vars = [col for col in self._nonnormal_vars if col not in to_remove]\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"Note: scipy not found - using simplified variable type detection.\")\n",
    "            print(\"Install scipy for better detection of normal vs non-normal variables.\")\n",
    "            print(\"  pip install scipy\")\n",
    "        \n",
    "        # Print helpful message\n",
    "        print(f\"Auto-detected {len(self._categorical_vars)} categorical, {len(self._normal_vars)} normal, and {len(self._nonnormal_vars)} non-normal variables.\")\n",
    "        print(\"You can customize these with .categorize(), .measure_normal(), and .measure_nonnormal() methods.\")\n",
    "    \n",
    "    def categorize(self, variables: List[str]):\n",
    "        \"\"\"\n",
    "        Define categorical variables to include in the analysis.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        variables : List[str]\n",
    "            List of column names to treat as categorical\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : EasyFlow\n",
    "            For method chaining\n",
    "        \"\"\"\n",
    "        self._categorical_vars = variables\n",
    "        return self\n",
    "    \n",
    "    def measure_normal(self, variables: List[str]):\n",
    "        \"\"\"\n",
    "        Define normally distributed variables to include in the analysis.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        variables : List[str]\n",
    "            List of column names of normally distributed variables\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : EasyFlow\n",
    "            For method chaining\n",
    "        \"\"\"\n",
    "        self._normal_vars = variables\n",
    "        return self\n",
    "    \n",
    "    def measure_nonnormal(self, variables: List[str]):\n",
    "        \"\"\"\n",
    "        Define non-normally distributed variables to include in the analysis.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        variables : List[str]\n",
    "            List of column names of non-normally distributed variables\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : EasyFlow\n",
    "            For method chaining\n",
    "        \"\"\"\n",
    "        self._nonnormal_vars = variables\n",
    "        return self\n",
    "    \n",
    "    def _generate_exclusion_label(self, mask):\n",
    "        \"\"\"\n",
    "        Generate a user-friendly label from a pandas mask condition.\n",
    "        \"\"\"\n",
    "        # Try to extract code from the mask if possible\n",
    "        try:\n",
    "            mask_str = inspect.getsource(mask.func if hasattr(mask, 'func') else mask)\n",
    "            # Clean up the code to make a readable label\n",
    "            mask_str = mask_str.strip()\n",
    "            \n",
    "            # Extract condition from common patterns\n",
    "            condition_pattern = r'data\\[\"([^\"]+)\"\\]\\s*([<>=!]+)\\s*([^\\s]+)'\n",
    "            match = re.search(condition_pattern, mask_str)\n",
    "            \n",
    "            if match:\n",
    "                column, operator, value = match.groups()\n",
    "                return f\"{column} {operator} {value}\"\n",
    "            \n",
    "            return \"Exclusion criteria\"\n",
    "        except:\n",
    "            return \"Exclusion criteria\"\n",
    "    \n",
    "    def exclude(self, mask, label: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Add an exclusion step based on a boolean mask.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        mask : pandas.Series\n",
    "            Boolean mask to select the subset of data to keep\n",
    "        label : str, optional\n",
    "            Label describing the exclusion. If not provided, tries to generate one.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : EasyFlow\n",
    "            For method chaining\n",
    "        \"\"\"\n",
    "        # Generate label if not provided\n",
    "        if label is None:\n",
    "            label = self._generate_exclusion_label(mask)\n",
    "        \n",
    "        # Apply the mask to the current data\n",
    "        new_data = self._current_data[mask]\n",
    "        \n",
    "        # Store the step information\n",
    "        self._exclusion_steps.append({\n",
    "            'previous_data': self._current_data,\n",
    "            'mask': mask,\n",
    "            'new_data': new_data,\n",
    "            'label': label\n",
    "        })\n",
    "        \n",
    "        # Update current data\n",
    "        self._current_data = new_data\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _create_equiflow(self):\n",
    "        \"\"\"\n",
    "        Create and configure the underlying EquiFlow instance.\n",
    "        \"\"\"\n",
    "        # Create initial EquiFlow instance with the original data\n",
    "        ef = EquiFlow(\n",
    "            data=self.data,\n",
    "            initial_cohort_label=self.title,\n",
    "            categorical=self._categorical_vars,\n",
    "            normal=self._normal_vars,\n",
    "            nonnormal=self._nonnormal_vars\n",
    "        )\n",
    "        \n",
    "        # Add all exclusion steps\n",
    "        for i, step in enumerate(self._exclusion_steps):\n",
    "            # For the first step, pass the mask directly\n",
    "            if i == 0:\n",
    "                ef.add_exclusion(\n",
    "                    mask=step['mask'],\n",
    "                    exclusion_reason=step['label'],\n",
    "                    new_cohort_label=f\"Step {i+1}\"\n",
    "                )\n",
    "            else:\n",
    "                # For subsequent steps, we need to apply the mask to the current data\n",
    "                # since the original mask was for a different dataframe\n",
    "                indices = step['previous_data'][step['mask']].index\n",
    "                next_mask = self.data.index.isin(indices)\n",
    "                ef.add_exclusion(\n",
    "                    mask=next_mask,\n",
    "                    exclusion_reason=step['label'],\n",
    "                    new_cohort_label=f\"Step {i+1}\"\n",
    "                )\n",
    "        \n",
    "        self._equiflow = ef\n",
    "        return ef\n",
    "    \n",
    "    def generate(self, output: str = \"flow_diagram\", show: bool = True, format: str = \"pdf\"):\n",
    "        \"\"\"\n",
    "        Generate the flow diagram and tables.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        output : str, optional\n",
    "            Base name for output files\n",
    "        show : bool, optional\n",
    "            Whether to display the flow diagram\n",
    "        format : str, optional\n",
    "            Output format for the diagram (pdf, svg, png)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : EasyFlow\n",
    "            For method chaining\n",
    "        \"\"\"\n",
    "        # Create EquiFlow instance if not already created\n",
    "        if self._equiflow is None:\n",
    "            ef = self._create_equiflow()\n",
    "        else:\n",
    "            ef = self._equiflow\n",
    "        \n",
    "        # Get tables\n",
    "        self.flow_table = ef.view_table_flows()\n",
    "        self.characteristics = ef.view_table_characteristics()\n",
    "        self.drifts = ef.view_table_drifts()\n",
    "        \n",
    "        # Generate and save the diagram\n",
    "        ef.plot_flows(\n",
    "            output_file=output,\n",
    "            display_flow_diagram=show\n",
    "        )\n",
    "        \n",
    "        # Store the diagram path for reference\n",
    "        self.diagram = os.path.join(\"imgs\", f\"{output}.{format}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    @classmethod\n",
    "    def quick_flow(cls, \n",
    "                  data: pd.DataFrame, \n",
    "                  exclusions: List[Tuple[pd.Series, str]], \n",
    "                  output: str = \"flow_diagram\",\n",
    "                  auto_detect: bool = True):\n",
    "        \"\"\"\n",
    "        Quickly create a flow diagram with a list of exclusion steps.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Initial cohort data\n",
    "        exclusions : List[Tuple[pd.Series, str]]\n",
    "            List of (mask, label) pairs defining exclusions\n",
    "        output : str, optional\n",
    "            Base name for output files\n",
    "        auto_detect : bool, optional\n",
    "            Whether to auto-detect variable types\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        flow : EasyFlow\n",
    "            The configured EasyFlow instance\n",
    "        \"\"\"\n",
    "        # Create EasyFlow instance\n",
    "        flow = cls(data, auto_detect=auto_detect)\n",
    "        \n",
    "        # Add all exclusion steps\n",
    "        for mask, label in exclusions:\n",
    "            flow.exclude(mask, label)\n",
    "        \n",
    "        # Generate the diagram\n",
    "        flow.generate(output=output)\n",
    "        \n",
    "        return flow\n",
    "\n",
    "\n",
    "# Example usage of the quick_flow method:\n",
    "# \n",
    "# data = pd.read_csv(\"patients.csv\")\n",
    "# exclusions = [\n",
    "#     (data[\"age\"] >= 18, \"Age < 18 years\"),\n",
    "#     (data[\"consent\"] == \"yes\", \"No consent\"),\n",
    "#     (data[\"complete_data\"] == True, \"Incomplete data\")\n",
    "# ]\n",
    "# \n",
    "# flow = EasyFlow.quick_flow(data, exclusions, output=\"patient_diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing required packages: scipy\n",
      "The example will continue but some functionality may be limited.\n",
      "To install missing packages, run:\n",
      "  pip install scipy\n",
      "\n",
      "\n",
      "Creating flow diagram using the fluent interface...\n",
      "Note: scipy not found - using simplified variable type detection.\n",
      "Install scipy for better detection of normal vs non-normal variables.\n",
      "  pip install scipy\n",
      "Auto-detected 4 categorical, 0 normal, and 4 non-normal variables.\n",
      "You can customize these with .categorize(), .measure_normal(), and .measure_nonnormal() methods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/dmt639hd4zqck2f7f3v313j00000gn/T/ipykernel_44100/3020666813.py:227: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  new_data = self._current_data[mask]\n",
      "/var/folders/bz/dmt639hd4zqck2f7f3v313j00000gn/T/ipykernel_44100/3020666813.py:267: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  indices = step['previous_data'][step['mask']].index\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 1000 instead of 847",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Method 1: Using the fluent interface\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating flow diagram using the fluent interface...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m flow \u001b[38;5;241m=\u001b[39m (\u001b[43mEasyFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPatient Selection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbmi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure_nonnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlos_days\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRemoved patients under 18 years\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconsent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExcluded non-consenting patients\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmissing_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRemoved records with missing data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatient_selection_diagram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAccessing results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlow table shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflow\u001b[38;5;241m.\u001b[39mflow_table\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 298\u001b[0m, in \u001b[0;36mEasyFlow.generate\u001b[0;34m(self, output, show, format)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Create EquiFlow instance if not already created\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_equiflow \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     ef \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_equiflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     ef \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_equiflow\n",
      "Cell \u001b[0;32mIn[4], line 269\u001b[0m, in \u001b[0;36mEasyFlow._create_equiflow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m         indices \u001b[38;5;241m=\u001b[39m step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprevious_data\u001b[39m\u001b[38;5;124m'\u001b[39m][step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m    268\u001b[0m         next_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(indices)\n\u001b[0;32m--> 269\u001b[0m         \u001b[43mef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_exclusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnext_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexclusion_reason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnew_cohort_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStep \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_equiflow \u001b[38;5;241m=\u001b[39m ef\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ef\n",
      "File \u001b[0;32m~/Desktop/equiflow-v2/equiflow/equiflow.py:151\u001b[0m, in \u001b[0;36mEquiFlow.add_exclusion\u001b[0;34m(self, mask, new_cohort, exclusion_reason, new_cohort_label)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one of mask or new_cohort must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dfs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_cohort \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;66;03m# first make sure that the new cohort has the same columns as the previous one\u001b[39;00m\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(new_cohort\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;241m.\u001b[39missubset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dfs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "File \u001b[0;32m~/Desktop/equiflow-v2/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/equiflow-v2/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1413\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[0;32m~/Desktop/equiflow-v2/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1209\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_getbool_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: AxisInt):\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;66;03m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 1209\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m     inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/Desktop/equiflow-v2/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:2681\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[1;32m   2680\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd_array(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m-> 2681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/equiflow-v2/.venv/lib/python3.10/site-packages/pandas/core/indexers/utils.py:539\u001b[0m, in \u001b[0;36mcheck_array_indexer\u001b[0;34m(array, indexer)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[0;32m--> 539\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoolean index has wrong length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m         )\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: Boolean index has wrong length: 1000 instead of 847"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check required packages and install if necessary\n",
    "required_packages = ['scipy']\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"Missing required packages: {', '.join(missing_packages)}\")\n",
    "    print(\"The example will continue but some functionality may be limited.\")\n",
    "    print(\"To install missing packages, run:\")\n",
    "    print(f\"  pip install {' '.join(missing_packages)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Import our package\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "# Create a sample dataset (simulates patient data)\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    # Demographic data\n",
    "    'age': np.random.normal(45, 15, n),\n",
    "    'gender': np.random.choice(['Male', 'Female', 'Other'], n, p=[0.48, 0.49, 0.03]),\n",
    "    'race': np.random.choice(['White', 'Black', 'Asian', 'Hispanic', 'Other'], n),\n",
    "    \n",
    "    # Clinical data\n",
    "    'bmi': np.random.normal(27, 5, n),\n",
    "    'los_days': np.random.exponential(5, n),  # Length of stay (days)\n",
    "    'cost': np.random.exponential(10000, n),  # Cost in dollars\n",
    "    \n",
    "    # Study-specific data\n",
    "\n",
    "    'consent': np.random.choice(['yes', 'no'], n, p=[0.85, 0.15]),\n",
    "    'missing_data': np.random.choice([True, False], n, p=[0.75, 0.25])\n",
    "})\n",
    "\n",
    "# Add some constraints to make the data more realistic\n",
    "data['age'] = data['age'].clip(18, 95).round(0)\n",
    "data['bmi'] = data['bmi'].clip(15, 50).round(1)\n",
    "data['los_days'] = data['los_days'].clip(1, 30).round(1)\n",
    "data['cost'] = data['cost'].clip(1000, 100000).round(-2)\n",
    "\n",
    "# Method 1: Using the fluent interface\n",
    "print(\"Creating flow diagram using the fluent interface...\")\n",
    "flow = (EasyFlow(data, title=\"Patient Selection\")\n",
    "    .categorize([\"gender\", \"race\"])\n",
    "    .measure_normal([\"age\", \"bmi\"])\n",
    "    .measure_nonnormal([\"los_days\", \"cost\"])\n",
    "    .exclude(data[\"age\"] >= 18, \"Removed patients under 18 years\")\n",
    "    .exclude(data[\"consent\"] == \"yes\", \"Excluded non-consenting patients\")\n",
    "    .exclude(data[\"missing_data\"] == True, \"Removed records with missing data\")\n",
    "    .generate(output=\"patient_selection_diagram\")\n",
    ")\n",
    "\n",
    "print(\"\\nAccessing results:\")\n",
    "print(f\"Flow table shape: {flow.flow_table.shape}\")\n",
    "print(f\"Characteristics table shape: {flow.characteristics.shape}\")\n",
    "print(f\"Drifts table shape: {flow.drifts.shape}\")\n",
    "print(f\"Diagram saved to: {flow.diagram}\")\n",
    "\n",
    "# Method 2: Using the quick_flow method\n",
    "print(\"\\nCreating flow diagram using the quick_flow method...\")\n",
    "exclusions = [\n",
    "    (data[\"age\"] >= 18, \"Age < 18 years\"),\n",
    "    (data[\"consent\"] == \"yes\", \"No consent\"),\n",
    "    (data[\"missing_data\"] == True, \"Complete data only\")\n",
    "]\n",
    "\n",
    "quick_flow = EasyFlow.quick_flow(\n",
    "    data, \n",
    "    exclusions=exclusions, \n",
    "    output=\"quick_flow_diagram\"\n",
    ")\n",
    "\n",
    "print(f\"\\nQuick flow diagram saved to: {quick_flow.diagram}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
